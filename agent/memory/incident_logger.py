"""Incident logging system for building operational knowledge"""
import json
from datetime import datetime
from pathlib import Path
from agent.memory.vector_store import VectorStore


class IncidentLogger:
    """Records and retrieves operational incidents for institutional knowledge"""
    
    def __init__(self, 
                 vector_store_path="agent/memory/faiss.index",
                 incident_log_path="agent/logs/incidents.jsonl"):
        self.vector_store = VectorStore()
        self.incident_log_path = Path(incident_log_path)
        self.incident_log_path.parent.mkdir(parents=True, exist_ok=True)
    
    def log_incident(self, query, plan, results, outcome="unknown", notes=""):
        """
        Log an operational incident
        
        Args:
            query: User's original query
            plan: The plan generated by the planner
            results: Execution results
            outcome: success/failure/partial
            notes: Additional notes or solution details
        """
        incident = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "goal": plan.get("goal", ""),
            "tools_used": plan.get("tools", []),
            "reasoning": plan.get("reasoning", ""),
            "outcome": outcome,
            "notes": notes,
            "tools_executed": len(results.get("results", [])),
            "success_count": sum(1 for r in results.get("results", []) 
                               if r.get("success"))
        }
        
        # Create searchable text representation
        search_text = self._create_search_text(incident)
        
        # Add to vector store for semantic search
        metadata = {
            "type": "incident",
            "timestamp": incident["timestamp"],
            "query": query,
            "goal": incident["goal"],
            "outcome": outcome,
            "tools": incident["tools_used"]
        }
        
        self.vector_store.add(search_text, metadata)
        self.vector_store.save()
        
        # Append to JSONL log for full details
        with open(self.incident_log_path, 'a') as f:
            f.write(json.dumps(incident) + "\n")
        
        return incident
    
    def _create_search_text(self, incident):
        """Create searchable text from incident"""
        parts = [
            f"Query: {incident['query']}",
            f"Goal: {incident['goal']}",
            f"Reasoning: {incident['reasoning']}",
            f"Outcome: {incident['outcome']}"
        ]
        
        if incident.get('notes'):
            parts.append(f"Notes: {incident['notes']}")
        
        return " | ".join(parts)
    
    def search_similar_incidents(self, query, k=5):
        """
        Search for similar past incidents
        
        Args:
            query: Search query
            k: Number of results
            
        Returns:
            List of (metadata, similarity) tuples
        """
        return self.vector_store.search(query, k=k)
    
    def get_recent_incidents(self, n=10):
        """Get the most recent incidents from JSONL log"""
        if not self.incident_log_path.exists():
            return []
        
        incidents = []
        with open(self.incident_log_path) as f:
            for line in f:
                try:
                    incidents.append(json.loads(line))
                except:
                    pass
        
        return incidents[-n:]
    
    def get_statistics(self):
        """Get statistics about logged incidents"""
        if not self.incident_log_path.exists():
            return {
                "total_incidents": 0,
                "vector_count": self.vector_store.count()
            }
        
        incidents = []
        with open(self.incident_log_path) as f:
            for line in f:
                try:
                    incidents.append(json.loads(line))
                except:
                    pass
        
        if not incidents:
            return {
                "total_incidents": 0,
                "vector_count": self.vector_store.count()
            }
        
        # Calculate statistics
        outcomes = {}
        tools_usage = {}
        
        for inc in incidents:
            outcome = inc.get("outcome", "unknown")
            outcomes[outcome] = outcomes.get(outcome, 0) + 1
            
            for tool in inc.get("tools_used", []):
                tools_usage[tool] = tools_usage.get(tool, 0) + 1
        
        return {
            "total_incidents": len(incidents),
            "vector_count": self.vector_store.count(),
            "outcomes": outcomes,
            "most_used_tools": sorted(tools_usage.items(), 
                                     key=lambda x: x[1], reverse=True)[:5],
            "first_incident": incidents[0]["timestamp"],
            "latest_incident": incidents[-1]["timestamp"]
        }


if __name__ == "__main__":
    # Test the incident logger
    print("Testing Incident Logger...")
    
    logger = IncidentLogger()
    
    # Log a test incident
    test_plan = {
        "goal": "Identify disk space issues",
        "tools": ["disk_usage", "process_list"],
        "reasoning": "Check disk and processes"
    }
    
    test_results = {
        "results": [
            {"tool": "disk_usage", "success": True},
            {"tool": "process_list", "success": True}
        ]
    }
    
    print("\nLogging test incident...")
    incident = logger.log_incident(
        query="Why is my disk filling up?",
        plan=test_plan,
        results=test_results,
        outcome="success",
        notes="Found /tmp was full, cleaned up successfully"
    )
    
    print(f"Logged incident at {incident['timestamp']}")
    
    # Search for similar
    print("\n" + "="*60)
    print("Searching for similar incidents...")
    print("="*60)
    
    similar = logger.search_similar_incidents("disk space problem", k=3)
    
    for i, (meta, score) in enumerate(similar, 1):
        print(f"\nResult {i} (similarity: {score:.3f}):")
        print(f"  Query: {meta.get('query', 'N/A')}")
        print(f"  Goal: {meta.get('goal', 'N/A')}")
        print(f"  Outcome: {meta.get('outcome', 'N/A')}")
        print(f"  Type: {meta.get('type', 'old_test_data')}")
    
    # Get statistics
    print("\n" + "="*60)
    stats = logger.get_statistics()
    print("Statistics:")
    print(f"  Total incidents: {stats['total_incidents']}")
    print(f"  Vectors stored: {stats['vector_count']}")
    
    print("\nIncident logger test complete!")
